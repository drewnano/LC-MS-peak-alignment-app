{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excipient Compatibility Data Extraction and Curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook is meant for the analysis of excipient compatibility data previously done with BioAssay\n",
    "It consists of multiple steps:*\n",
    "1. Upload of .csv files as generated by Empower\n",
    "2. Reformatting of the data for analysis using dataframes\n",
    "3. Calculation of relative retention times and binning of retention times\n",
    "4. Attribution of retention time shifts and probabilty assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload of Degradation Data (Week 0-5, wet/dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Modules\n",
    "import pandas as pd #handling of csv files and dataframes\n",
    "import numpy as np\n",
    "import ipywidgets as widgets # widgets for displaying in voila\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bbdca0b7fd4a2295bb47213f0b3701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a FileUpload widget\n",
    "file_upload = widgets.FileUpload(multiple=True)\n",
    "\n",
    "# Display the widget\n",
    "display(file_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part was an attempt of having an interface to click and select files \n",
    "#It does currently not work\n",
    "\n",
    "from tk import  Checkbutton, Button, IntVar\n",
    "\n",
    "def get_selected_items():\n",
    "    global csv_file_path\n",
    "    selected_items = [item.get() for item in checkbox_vars]\n",
    "    csv_file_path = []\n",
    "    print(\"Selected items:\", selected_items)\n",
    "    for j,counter in enumerate(selected_items):\n",
    "        if counter==True:\n",
    "            csv_file_path.append(filedialog.askopenfilename(title=\"Select CSV File for \", filetypes=[(\"CSV Files\", \"*.csv\")]))\n",
    "            # Display the selected file path\n",
    "            print(\"Selected CSV File for \",checkbox_names[j], \" is: \", csv_file_path[j])\n",
    "        else: csv_file_path.append(\"0\")\n",
    "    root.quit()\n",
    "\n",
    "# Create the Tkinter root window\n",
    "root = Tk()\n",
    "\n",
    "# Create tkinter IntVar variables to store the state of the checkboxes\n",
    "checkbox_vars = [IntVar() for _ in range(6)]\n",
    "checkbox_names = [\"Week0\",\"Week0_humid\",\"Week2\",\"Week2_humid\",\"Week5\",\"Week5_humid\"]\n",
    "\n",
    "# Create the checkboxes\n",
    "checkboxes = []\n",
    "for i, var in enumerate(checkbox_vars):\n",
    "    checkbox = Checkbutton(root, text=checkbox_names[i], variable=var)\n",
    "    checkbox.pack()\n",
    "    checkboxes.append(checkbox)\n",
    "\n",
    "# Create a button to get the selected items\n",
    "button = Button(root, text=\"Get Selected Items\", command=get_selected_items)\n",
    "button.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of xlsx-files and reformatting of dataframe - Week2 loaded as example\n",
    "df = pd.read_excel(\"C:/Users/dejejord/OneDrive - Merck Sharp & Dohme LLC/Desktop/ExcipientCompatibility_Jupyter/Week2_Trimmed.xlsx\")\n",
    "\n",
    "#Trim down to most important columns\n",
    "df1 = df[[\"Vial\",\"Retention Time\", \"Area\"]]\n",
    "\n",
    "#Get relative retention times by division by retention time of largest area peak ==> Caveat: largest area needs to be API peak\n",
    "max_area = df1[\"Area\"].max()\n",
    "max_area_row=df1[df1[\"Area\"] == max_area]\n",
    "max_Ret_value = max_area_row[\"Retention Time\"].iloc[0]\n",
    "df1[\"Retention Time\"] = df1[\"Retention Time\"] / max_Ret_value\n",
    "\n",
    "#Pivot dataframe to be sorted by retention times\n",
    "df1=df1.round(2)\n",
    "pivot_df1 = df1.pivot_table(index=\"Vial\", columns=\"Retention Time\", values=\"Area\",aggfunc='sum')\n",
    "pivot_df1[np.isnan(pivot_df1)] = 0\n",
    "\n",
    "#Merge relative retention times if difference is 0.01 and no entry recorded for one of two columns for each well\n",
    "df_merged = pd.DataFrame()\n",
    "col_del = []\n",
    "columns = pivot_df1.columns.tolist()\n",
    "c=0\n",
    "\n",
    "while c <= len(columns)-2:\n",
    "    merge_condition = False\n",
    "    for index,row in pivot_df1.iterrows():\n",
    "        if round((columns[c+1]-columns[c]),2)==0.01:\n",
    "            if (row[columns[c+1]] != 0.0 and row[columns[c]] == 0.0) or (row[columns[c+1]] == 0.0 and row[columns[c]] != 0.0):\n",
    "                merge_condition = True\n",
    "                df_merged[columns[c]] =  pivot_df1[columns[c]]+pivot_df1[columns[c+1]]\n",
    "                c=c+2\n",
    "                break\n",
    "    if merge_condition == False:\n",
    "        df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "        c=c+1\n",
    "if c == len(columns)-1:\n",
    "    df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "\n",
    "\n",
    "#Normalize by API peak area\n",
    "final_norm = df_merged.div(df_merged[df_merged.columns[df_merged.columns == 0.99]].values,axis=0)\n",
    "final_norm=final_norm.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index([\"Vial\"])[\"SampleName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_counts = np.count_nonzero(df_merged, axis=0)\n",
    "result = pd.Series(non_zero_counts, index=df_merged.columns)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
