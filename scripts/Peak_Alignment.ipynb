{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS peak align "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Modules\n",
    "import pandas as pd #handling of csv files and dataframes\n",
    "import numpy as np\n",
    "from msalign import msalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sinegraa\\Downloads\n"
     ]
    }
   ],
   "source": [
    "# print working directory\n",
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 SampleName    Vial  Retention Time       Area     Height  \\\n",
      "0           9  2Week_40C   1:A,1          12.673   217673.0     4168.0   \n",
      "1          10  2Week_40C   1:A,1           9.939    16884.0     3738.0   \n",
      "2          13  2Week_40C   1:A,1           8.904  4405299.0  1029144.0   \n",
      "3         135  2Week_40C  1:A,10           8.906  4743392.0  1098051.0   \n",
      "4         136  2Week_40C  1:A,10           9.940    18490.0     4110.0   \n",
      "5         118  2Week_40C  1:A,11           8.914  4287113.0   998123.0   \n",
      "6         119  2Week_40C  1:A,11           9.949    16371.0     3642.0   \n",
      "7         123  2Week_40C  1:A,12           8.918  5890075.0  1357347.0   \n",
      "8         126  2Week_40C  1:A,12           9.946    22715.0     5008.0   \n",
      "9          23  2Week_40C   1:A,2           9.939    24013.0     5314.0   \n",
      "\n",
      "  Peak Type          Name  Injection  \\\n",
      "0   Unknown           NaN          1   \n",
      "1     Found  API_Impurity          1   \n",
      "2     Found           API          1   \n",
      "3   Unknown           NaN          1   \n",
      "4   Unknown           NaN          1   \n",
      "5     Found           API          1   \n",
      "6     Found  API_Impurity          1   \n",
      "7     Found           API          1   \n",
      "8     Found  API_Impurity          1   \n",
      "9     Found  API_Impurity          1   \n",
      "\n",
      "                             Date Processed  \\\n",
      "0  Wednesday, April 24, 2024 3:31:20 PM EDT   \n",
      "1  Wednesday, April 24, 2024 3:31:20 PM EDT   \n",
      "2  Wednesday, April 24, 2024 3:31:20 PM EDT   \n",
      "3  Wednesday, April 24, 2024 4:31:35 PM EDT   \n",
      "4  Wednesday, April 24, 2024 4:31:35 PM EDT   \n",
      "5  Wednesday, April 24, 2024 3:31:23 PM EDT   \n",
      "6  Wednesday, April 24, 2024 3:31:23 PM EDT   \n",
      "7  Wednesday, April 24, 2024 3:31:24 PM EDT   \n",
      "8  Wednesday, April 24, 2024 3:31:24 PM EDT   \n",
      "9  Wednesday, April 24, 2024 3:31:20 PM EDT   \n",
      "\n",
      "                            Date Acquired Processing Method  \\\n",
      "0  Monday, April 22, 2024 12:11:18 PM EDT        EC_L254_PM   \n",
      "1  Monday, April 22, 2024 12:11:18 PM EDT        EC_L254_PM   \n",
      "2  Monday, April 22, 2024 12:11:18 PM EDT        EC_L254_PM   \n",
      "3   Monday, April 22, 2024 3:43:18 PM EDT        EC_L254_PM   \n",
      "4   Monday, April 22, 2024 3:43:18 PM EDT        EC_L254_PM   \n",
      "5   Monday, April 22, 2024 3:07:53 PM EDT        EC_L254_PM   \n",
      "6   Monday, April 22, 2024 3:07:53 PM EDT        EC_L254_PM   \n",
      "7   Monday, April 22, 2024 3:25:35 PM EDT        EC_L254_PM   \n",
      "8   Monday, April 22, 2024 3:25:35 PM EDT        EC_L254_PM   \n",
      "9  Monday, April 22, 2024 12:28:56 PM EDT        EC_L254_PM   \n",
      "\n",
      "   Channel Description  \n",
      "0  PDA Ch1 210nm@2.4nm  \n",
      "1  PDA Ch1 210nm@2.4nm  \n",
      "2  PDA Ch1 210nm@2.4nm  \n",
      "3  PDA Ch1 210nm@2.4nm  \n",
      "4  PDA Ch1 210nm@2.4nm  \n",
      "5  PDA Ch1 210nm@2.4nm  \n",
      "6  PDA Ch1 210nm@2.4nm  \n",
      "7  PDA Ch1 210nm@2.4nm  \n",
      "8  PDA Ch1 210nm@2.4nm  \n",
      "9  PDA Ch1 210nm@2.4nm  \n"
     ]
    }
   ],
   "source": [
    "#loading data \n",
    "data = pd.read_excel('Week2_Trimmed.xlsx')\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split vial column into plate and coordinate columns by the : in the vial column and remove the original vial column\n",
    "data[['Plate','Coordinate']] = data['Vial'].str.split(':',expand=True)\n",
    "#remove comma from coordinate column entries\n",
    "data['Coordinate'] = data['Coordinate'].str.replace(',','')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this point, prompt user to ask which vial you want to align the peaks to, then call the retention time of those peaks so we can put them into the MSAlign package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which coordinate would you like to align the data to?\n",
      "Options are: A1, B2...\n"
     ]
    }
   ],
   "source": [
    "#promt user to ask which coordinate to align the data to\n",
    "print('Which coordinate would you like to align the data to?')\n",
    "print('Options are: A1, B2...')\n",
    "coordinate = input('Enter your choice: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.9, 8.911, 9.925, 9.939]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data based on the selected coordinate\n",
    "filtered_data = data[data['Coordinate'] == coordinate]\n",
    "\n",
    "# Sort the filtered data by area in descending order\n",
    "sorted_data = filtered_data.sort_values('Area', ascending=False)\n",
    "\n",
    "# Get the retention times of the top four peaks\n",
    "retention_times = sorted_data['Retention Time'].head(4).tolist()\n",
    "\n",
    "# Print the retention times\n",
    "retention_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe from data, only with retention time, sample name and area columns\n",
    "#using Height as a placeholder for now\n",
    "datafiltered = data[['Retention Time', 'SampleName', 'Height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_data = data.pivot(index='Retention Time', columns='SampleName', values='Area')\n",
    "reversed_data.columns.name = None\n",
    "reversed_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "datanp = data.to_numpy()\n",
    "x = datanp[1:,0]\n",
    "array = datanp[1:,1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2Week_40C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# run the msalign function with the retention times\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m aligned_array \u001b[38;5;241m=\u001b[39m \u001b[43mmsalign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretention_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\msalign\\__init__.py:47\u001b[0m, in \u001b[0;36mmsalign\u001b[1;34m(x, array, peaks, method, width, ratio, resolution, iterations, grid_steps, shift_range, weights, return_shifts, align_by_index, only_shift)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmsalign\u001b[39m(\n\u001b[0;32m     16\u001b[0m     x: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     17\u001b[0m     array: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     only_shift: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     30\u001b[0m ):\n\u001b[0;32m     31\u001b[0m     aligner \u001b[38;5;241m=\u001b[39m Aligner(\n\u001b[0;32m     32\u001b[0m         x,\n\u001b[0;32m     33\u001b[0m         array,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m         only_shift\u001b[38;5;241m=\u001b[39monly_shift,\n\u001b[0;32m     46\u001b[0m     )\n\u001b[1;32m---> 47\u001b[0m     \u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aligner\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\msalign\\align.py:291\u001b[0m, in \u001b[0;36mAligner.run\u001b[1;34m(self, n_iterations)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# main loop: searches for the optimum values of Scale and Shift factors by search over a multi-resolution\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# grid, getting better at each iteration. Increasing the number of iterations improves the shift and scale\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# parameters\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_signal, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray):\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshift_opt[n_signal], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_opt[n_signal] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_signals\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m signals \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m time_loop(t_start, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_signals \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_signals))\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\msalign\\align.py:310\u001b[0m, in \u001b[0;36mAligner.compute\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    306\u001b[0m _scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_range\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# generate interpolation function for each signal - instantiation of the interpolator can be quite slow,\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# so you can slightly increase the number of iterations without significant slowdown of the process\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# iterate to estimate the shift and scale - at each iteration, the grid search is readjusted and the\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# shift/scale values are optimized further\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iterations):\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# scale and shift search space\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\msalign\\utilities.py:131\u001b[0m, in \u001b[0;36mgenerate_function\u001b[1;34m(method, x, y)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpchip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m interpolate\u001b[38;5;241m.\u001b[39mPchipInterpolator(x, y, extrapolate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minterpolate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterp1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\interpolate\\_interpolate.py:525\u001b[0m, in \u001b[0;36minterp1d.__init__\u001b[1;34m(self, x, y, kind, axis, copy, bounds_error, fill_value, assume_sorted)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# Force-cast y to a floating-point type, if it's not yet one\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m--> 525\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Backward compatibility\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m%\u001b[39m y\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2Week_40C'"
     ]
    }
   ],
   "source": [
    "# run the msalign function with the retention times\n",
    "aligned_array = msalign(x,array, retention_times, weights=[100,100], only_shift=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by storing file locally in my local directory\n",
    "# once we have this working, we can replace this with asking the user to upload the files\n",
    "#focus on saving the output to the same directory as the input file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am in favor of getting rid of what's below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Checkbutton' from 'tk' (C:\\Users\\sinegraa\\AppData\\Roaming\\Python\\Python310\\site-packages\\tk\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This part was an attempt of having an interface to click and select files \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#It does currently not work\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  Checkbutton, Button, IntVar\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_selected_items\u001b[39m():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m csv_file_path\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Checkbutton' from 'tk' (C:\\Users\\sinegraa\\AppData\\Roaming\\Python\\Python310\\site-packages\\tk\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# This part was an attempt of having an interface to click and select files \n",
    "#It does currently not work\n",
    "\n",
    "from tk import  Checkbutton, Button, IntVar\n",
    "\n",
    "def get_selected_items():\n",
    "    global csv_file_path\n",
    "    selected_items = [item.get() for item in checkbox_vars]\n",
    "    csv_file_path = []\n",
    "    print(\"Selected items:\", selected_items)\n",
    "    for j,counter in enumerate(selected_items):\n",
    "        if counter==True:\n",
    "            csv_file_path.append(filedialog.askopenfilename(title=\"Select CSV File for \", filetypes=[(\"CSV Files\", \"*.csv\")]))\n",
    "            # Display the selected file path\n",
    "            print(\"Selected CSV File for \",checkbox_names[j], \" is: \", csv_file_path[j])\n",
    "        else: csv_file_path.append(\"0\")\n",
    "    root.quit()\n",
    "\n",
    "# Create the Tkinter root window\n",
    "root = Tk()\n",
    "\n",
    "# Create tkinter IntVar variables to store the state of the checkboxes\n",
    "checkbox_vars = [IntVar() for _ in range(6)]\n",
    "checkbox_names = [\"Week0\",\"Week0_humid\",\"Week2\",\"Week2_humid\",\"Week5\",\"Week5_humid\"]\n",
    "\n",
    "# Create the checkboxes\n",
    "checkboxes = []\n",
    "for i, var in enumerate(checkbox_vars):\n",
    "    checkbox = Checkbutton(root, text=checkbox_names[i], variable=var)\n",
    "    checkbox.pack()\n",
    "    checkboxes.append(checkbox)\n",
    "\n",
    "# Create a button to get the selected items\n",
    "button = Button(root, text=\"Get Selected Items\", command=get_selected_items)\n",
    "button.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of xlsx-files and reformatting of dataframe - Week2 loaded as example\n",
    "df = pd.read_excel(\"C:/Users/dejejord/OneDrive - Merck Sharp & Dohme LLC/Desktop/ExcipientCompatibility_Jupyter/Week2_Trimmed.xlsx\")\n",
    "\n",
    "#Trim down to most important columns\n",
    "df1 = df[[\"Vial\",\"Retention Time\", \"Area\"]]\n",
    "\n",
    "#Get relative retention times by division by retention time of largest area peak ==> Caveat: largest area needs to be API peak\n",
    "max_area = df1[\"Area\"].max()\n",
    "max_area_row=df1[df1[\"Area\"] == max_area]\n",
    "max_Ret_value = max_area_row[\"Retention Time\"].iloc[0]\n",
    "df1[\"Retention Time\"] = df1[\"Retention Time\"] / max_Ret_value\n",
    "\n",
    "#Pivot dataframe to be sorted by retention times\n",
    "df1=df1.round(2)\n",
    "pivot_df1 = df1.pivot_table(index=\"Vial\", columns=\"Retention Time\", values=\"Area\",aggfunc='sum')\n",
    "pivot_df1[np.isnan(pivot_df1)] = 0\n",
    "\n",
    "#Merge relative retention times if difference is 0.01 and no entry recorded for one of two columns for each well\n",
    "df_merged = pd.DataFrame()\n",
    "col_del = []\n",
    "columns = pivot_df1.columns.tolist()\n",
    "c=0\n",
    "\n",
    "while c <= len(columns)-2:\n",
    "    merge_condition = False\n",
    "    for index,row in pivot_df1.iterrows():\n",
    "        if round((columns[c+1]-columns[c]),2)==0.01:\n",
    "            if (row[columns[c+1]] != 0.0 and row[columns[c]] == 0.0) or (row[columns[c+1]] == 0.0 and row[columns[c]] != 0.0):\n",
    "                merge_condition = True\n",
    "                df_merged[columns[c]] =  pivot_df1[columns[c]]+pivot_df1[columns[c+1]]\n",
    "                c=c+2\n",
    "                break\n",
    "    if merge_condition == False:\n",
    "        df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "        c=c+1\n",
    "if c == len(columns)-1:\n",
    "    df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "\n",
    "\n",
    "#Normalize by API peak area\n",
    "final_norm = df_merged.div(df_merged[df_merged.columns[df_merged.columns == 0.99]].values,axis=0)\n",
    "final_norm=final_norm.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index([\"Vial\"])[\"SampleName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_counts = np.count_nonzero(df_merged, axis=0)\n",
    "result = pd.Series(non_zero_counts, index=df_merged.columns)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
