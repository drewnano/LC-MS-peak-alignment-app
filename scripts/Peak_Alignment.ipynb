{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS peak align based on bioAssay peak alignment for excipient screening\n",
    "see nb-dejejord-5094579-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Modules\n",
    "import pandas as pd #handling of csv files and dataframes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data \n",
    "data = pd.read_excel('./exampledata/Week2_Trimmed.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-processing and qc steps\n",
    "return parent peak retention time median, min RT, max RT, enter global parent peak RT (optional)\n",
    "parent API peak cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[nan] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m areasum \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVial\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSum of Area\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m max_area_rows \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVial\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[1;32m----> 8\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmax_area_rows\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m mainpeakRT \u001b[38;5;241m=\u001b[39m filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetention Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m mainpeakarearatio \u001b[38;5;241m=\u001b[39m maxarea[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39mareasum[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSum of Area\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[nan] not in index'"
     ]
    }
   ],
   "source": [
    "#split vial column into before and after the colon into plate, and Vial columns\n",
    "data['Plate'] = data['Vial'].str.split(':').str[0]\n",
    "data['Vial'] = data['Vial'].str.split(':').str[1]\n",
    "df_vial_counts = data.groupby(['Plate', 'Vial']).size().reset_index(name='Count')\n",
    "maxarea = data.groupby(['Plate', 'Vial'])['Area'].max().reset_index()\n",
    "areasum = data.groupby(['Plate', 'Vial'])['Area'].sum().reset_index(name='Sum of Area')\n",
    "max_area_rows = data.groupby(['Plate', 'Vial'])['Area'].idxmax()\n",
    "filtered_data = data.loc[max_area_rows]\n",
    "mainpeakRT = filtered_data['Retention Time']\n",
    "mainpeakarearatio = maxarea['Area']/areasum['Sum of Area']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initialize empty list called peakcount\n",
    "peakcount = []\n",
    "for vial in data['Vial'].unique():\n",
    "    peackcount[i]=len(df[df['Vial'] == vial]).str.contains(vial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_data = data.pivot(index='Retention Time', columns='SampleName', values='Area')\n",
    "reversed_data.columns.name = None\n",
    "reversed_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "datanp = data.to_numpy()\n",
    "x = datanp[1:,0]\n",
    "array = datanp[1:,1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the msalign function with the retention times\n",
    "aligned_array = msalign(x,array, retention_times, weights=[100,100], only_shift=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by storing file locally in my local directory\n",
    "# once we have this working, we can replace this with asking the user to upload the files\n",
    "#focus on saving the output to the same directory as the input file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am in favor of getting rid of what's below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part was an attempt of having an interface to click and select files \n",
    "#It does currently not work\n",
    "\n",
    "from tk import  Checkbutton, Button, IntVar\n",
    "\n",
    "def get_selected_items():\n",
    "    global csv_file_path\n",
    "    selected_items = [item.get() for item in checkbox_vars]\n",
    "    csv_file_path = []\n",
    "    print(\"Selected items:\", selected_items)\n",
    "    for j,counter in enumerate(selected_items):\n",
    "        if counter==True:\n",
    "            csv_file_path.append(filedialog.askopenfilename(title=\"Select CSV File for \", filetypes=[(\"CSV Files\", \"*.csv\")]))\n",
    "            # Display the selected file path\n",
    "            print(\"Selected CSV File for \",checkbox_names[j], \" is: \", csv_file_path[j])\n",
    "        else: csv_file_path.append(\"0\")\n",
    "    root.quit()\n",
    "\n",
    "# Create the Tkinter root window\n",
    "root = Tk()\n",
    "\n",
    "# Create tkinter IntVar variables to store the state of the checkboxes\n",
    "checkbox_vars = [IntVar() for _ in range(6)]\n",
    "checkbox_names = [\"Week0\",\"Week0_humid\",\"Week2\",\"Week2_humid\",\"Week5\",\"Week5_humid\"]\n",
    "\n",
    "# Create the checkboxes\n",
    "checkboxes = []\n",
    "for i, var in enumerate(checkbox_vars):\n",
    "    checkbox = Checkbutton(root, text=checkbox_names[i], variable=var)\n",
    "    checkbox.pack()\n",
    "    checkboxes.append(checkbox)\n",
    "\n",
    "# Create a button to get the selected items\n",
    "button = Button(root, text=\"Get Selected Items\", command=get_selected_items)\n",
    "button.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of xlsx-files and reformatting of dataframe - Week2 loaded as example\n",
    "df = pd.read_excel(\"C:/Users/dejejord/OneDrive - Merck Sharp & Dohme LLC/Desktop/ExcipientCompatibility_Jupyter/Week2_Trimmed.xlsx\")\n",
    "\n",
    "#Trim down to most important columns\n",
    "df1 = df[[\"Vial\",\"Retention Time\", \"Area\"]]\n",
    "\n",
    "#Get relative retention times by division by retention time of largest area peak ==> Caveat: largest area needs to be API peak\n",
    "max_area = df1[\"Area\"].max()\n",
    "max_area_row=df1[df1[\"Area\"] == max_area]\n",
    "max_Ret_value = max_area_row[\"Retention Time\"].iloc[0]\n",
    "df1[\"Retention Time\"] = df1[\"Retention Time\"] / max_Ret_value\n",
    "\n",
    "#Pivot dataframe to be sorted by retention times\n",
    "df1=df1.round(2)\n",
    "pivot_df1 = df1.pivot_table(index=\"Vial\", columns=\"Retention Time\", values=\"Area\",aggfunc='sum')\n",
    "pivot_df1[np.isnan(pivot_df1)] = 0\n",
    "\n",
    "#Merge relative retention times if difference is 0.01 and no entry recorded for one of two columns for each well\n",
    "df_merged = pd.DataFrame()\n",
    "col_del = []\n",
    "columns = pivot_df1.columns.tolist()\n",
    "c=0\n",
    "\n",
    "while c <= len(columns)-2:\n",
    "    merge_condition = False\n",
    "    for index,row in pivot_df1.iterrows():\n",
    "        if round((columns[c+1]-columns[c]),2)==0.01:\n",
    "            if (row[columns[c+1]] != 0.0 and row[columns[c]] == 0.0) or (row[columns[c+1]] == 0.0 and row[columns[c]] != 0.0):\n",
    "                merge_condition = True\n",
    "                df_merged[columns[c]] =  pivot_df1[columns[c]]+pivot_df1[columns[c+1]]\n",
    "                c=c+2\n",
    "                break\n",
    "    if merge_condition == False:\n",
    "        df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "        c=c+1\n",
    "if c == len(columns)-1:\n",
    "    df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "\n",
    "\n",
    "#Normalize by API peak area\n",
    "final_norm = df_merged.div(df_merged[df_merged.columns[df_merged.columns == 0.99]].values,axis=0)\n",
    "final_norm=final_norm.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index([\"Vial\"])[\"SampleName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_counts = np.count_nonzero(df_merged, axis=0)\n",
    "result = pd.Series(non_zero_counts, index=df_merged.columns)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
