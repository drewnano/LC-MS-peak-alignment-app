{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MS peak align based on bioAssay peak alignment for excipient screening\n",
    "see nb-dejejord-5094579-001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Modules\n",
    "import pandas as pd #handling of csv files and dataframes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data \n",
    "data = pd.read_excel('./exampledata/Week2_Trimmed.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-processing and qc steps\n",
    "return parent peak retention time median, min RT, max RT, enter global parent peak RT (optional)\n",
    "parent API peak cutoff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split vial column into before and after the colon into plate, and Vial columns\n",
    "df_vial_counts = data.groupby(['Vial']).size().reset_index(name='peakCount')\n",
    "maxarea = data.groupby(['Vial'])['Area'].max().reset_index()\n",
    "areasum = data.groupby(['Vial'])['Area'].sum().reset_index(name='Sum of Area')\n",
    "maxarea['Area Sum'] = areasum['Sum of Area']\n",
    "maxarea['Area Ratio'] = maxarea['Area']/ maxarea['Area Sum']\n",
    "RTmax= (data.sort_values(['Vial', 'Area'], ascending=[True, False])\n",
    "             .drop_duplicates(['Vial']).reset_index(drop=True)\n",
    "          )\n",
    "maxarea = pd.merge(maxarea,RTmax,how = 'left', on = ['Vial', 'Area'])\n",
    "maxarea = pd.merge(maxarea,df_vial_counts, how = 'left', on = 'Vial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "median_retention_time = maxarea['Retention Time'].median()\n",
    "min_retention_time = maxarea['Retention Time'].min()\n",
    "max_retention_time = maxarea['Retention Time'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n"
     ]
    }
   ],
   "source": [
    "# Group the data by \"Vial\" and find the index of the row with the maximum \"Area\" for each group\n",
    "max_area_indices = data.groupby('Vial')['Area'].idxmax()\n",
    "print(max_area_indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'msalign' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# run the msalign function with the retention times\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m aligned_array \u001b[38;5;241m=\u001b[39m \u001b[43mmsalign\u001b[49m(x,array, retention_times, weights\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m], only_shift\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'msalign' is not defined"
     ]
    }
   ],
   "source": [
    "# run the msalign function with the retention times\n",
    "aligned_array = msalign(x,array, retention_times, weights=[100,100], only_shift=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by storing file locally in my local directory\n",
    "# once we have this working, we can replace this with asking the user to upload the files\n",
    "#focus on saving the output to the same directory as the input file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am in favor of getting rid of what's below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part was an attempt of having an interface to click and select files \n",
    "#It does currently not work\n",
    "\n",
    "from tk import  Checkbutton, Button, IntVar\n",
    "\n",
    "def get_selected_items():\n",
    "    global csv_file_path\n",
    "    selected_items = [item.get() for item in checkbox_vars]\n",
    "    csv_file_path = []\n",
    "    print(\"Selected items:\", selected_items)\n",
    "    for j,counter in enumerate(selected_items):\n",
    "        if counter==True:\n",
    "            csv_file_path.append(filedialog.askopenfilename(title=\"Select CSV File for \", filetypes=[(\"CSV Files\", \"*.csv\")]))\n",
    "            # Display the selected file path\n",
    "            print(\"Selected CSV File for \",checkbox_names[j], \" is: \", csv_file_path[j])\n",
    "        else: csv_file_path.append(\"0\")\n",
    "    root.quit()\n",
    "\n",
    "# Create the Tkinter root window\n",
    "root = Tk()\n",
    "\n",
    "# Create tkinter IntVar variables to store the state of the checkboxes\n",
    "checkbox_vars = [IntVar() for _ in range(6)]\n",
    "checkbox_names = [\"Week0\",\"Week0_humid\",\"Week2\",\"Week2_humid\",\"Week5\",\"Week5_humid\"]\n",
    "\n",
    "# Create the checkboxes\n",
    "checkboxes = []\n",
    "for i, var in enumerate(checkbox_vars):\n",
    "    checkbox = Checkbutton(root, text=checkbox_names[i], variable=var)\n",
    "    checkbox.pack()\n",
    "    checkboxes.append(checkbox)\n",
    "\n",
    "# Create a button to get the selected items\n",
    "button = Button(root, text=\"Get Selected Items\", command=get_selected_items)\n",
    "button.pack()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of xlsx-files and reformatting of dataframe - Week2 loaded as example\n",
    "df = pd.read_excel(\"C:/Users/dejejord/OneDrive - Merck Sharp & Dohme LLC/Desktop/ExcipientCompatibility_Jupyter/Week2_Trimmed.xlsx\")\n",
    "\n",
    "#Trim down to most important columns\n",
    "df1 = df[[\"Vial\",\"Retention Time\", \"Area\"]]\n",
    "\n",
    "#Get relative retention times by division by retention time of largest area peak ==> Caveat: largest area needs to be API peak\n",
    "max_area = df1[\"Area\"].max()\n",
    "max_area_row=df1[df1[\"Area\"] == max_area]\n",
    "max_Ret_value = max_area_row[\"Retention Time\"].iloc[0]\n",
    "df1[\"Retention Time\"] = df1[\"Retention Time\"] / max_Ret_value\n",
    "\n",
    "#Pivot dataframe to be sorted by retention times\n",
    "df1=df1.round(2)\n",
    "pivot_df1 = df1.pivot_table(index=\"Vial\", columns=\"Retention Time\", values=\"Area\",aggfunc='sum')\n",
    "pivot_df1[np.isnan(pivot_df1)] = 0\n",
    "\n",
    "#Merge relative retention times if difference is 0.01 and no entry recorded for one of two columns for each well\n",
    "df_merged = pd.DataFrame()\n",
    "col_del = []\n",
    "columns = pivot_df1.columns.tolist()\n",
    "c=0\n",
    "\n",
    "while c <= len(columns)-2:\n",
    "    merge_condition = False\n",
    "    for index,row in pivot_df1.iterrows():\n",
    "        if round((columns[c+1]-columns[c]),2)==0.01:\n",
    "            if (row[columns[c+1]] != 0.0 and row[columns[c]] == 0.0) or (row[columns[c+1]] == 0.0 and row[columns[c]] != 0.0):\n",
    "                merge_condition = True\n",
    "                df_merged[columns[c]] =  pivot_df1[columns[c]]+pivot_df1[columns[c+1]]\n",
    "                c=c+2\n",
    "                break\n",
    "    if merge_condition == False:\n",
    "        df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "        c=c+1\n",
    "if c == len(columns)-1:\n",
    "    df_merged[columns[c]] =  pivot_df1[columns[c]]\n",
    "\n",
    "\n",
    "#Normalize by API peak area\n",
    "final_norm = df_merged.div(df_merged[df_merged.columns[df_merged.columns == 0.99]].values,axis=0)\n",
    "final_norm=final_norm.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index([\"Vial\"])[\"SampleName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_counts = np.count_nonzero(df_merged, axis=0)\n",
    "result = pd.Series(non_zero_counts, index=df_merged.columns)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
